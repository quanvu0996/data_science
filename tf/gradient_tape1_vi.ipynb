{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/data_science/blob/main/tf/gradient_tape1_vi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient descent with tensorflow\n",
        "Các công cụ hỗ trợ xây dựng mô hình học máy, học sâu như tensorflow, pytorch ngày càng phổ biến. Xây dựng mô hình trở nên dễ dàng chỉ với một câu lệnh fit. Tuy nhiên để tối ưu hoặc sáng tạo kiến trúc mới người ta cần một công cụ linh động hơn như Gradient tape để huấn luyện các model có kiến trúc đặc biệt."
      ],
      "metadata": {
        "id": "ug_pOeYnUFHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wHwaYXU-XdB6",
        "outputId": "9108f6bf-8f98-4134-9a8b-95d5edd13d42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Một số khái niệm cơ bản của tensorflow\n",
        "**Hằng**: là một tensor có giá trị cố định. Có thể là một số (scalar- tensor 1 chiều), hoặc ma trận (tensor 2 chiều), hoặc tensor n-chiều"
      ],
      "metadata": {
        "id": "5VtIx_8hW5cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant(1)\n",
        "b = tf.constant([3, 5])\n",
        "c = tf.ones(shape=(2,2))\n",
        "\n",
        "print(a, b, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z16zz0meW9h8",
        "outputId": "1271f68a-7f08-4f49-dc50-74bd6ee7f916"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor([3 5], shape=(2,), dtype=int32) tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Biến**: là một đối tượng có thể thay đổi giá trị tùy thuộc dữ liệu đầu vào."
      ],
      "metadata": {
        "id": "vjzc3FKFYcAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.Variable(initial_value= tf.zeros((2, 2)), trainable= True)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-mboXvHUJBQ",
        "outputId": "8046d0d2-bb4b-4553-c777-8b559c1ca4a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              "array([[0., 0.],\n",
              "       [0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Những khái nhiệm này cũng tương ứng với các khái niệm trong đại số tuyến tính. <br>\n",
        "**Gradient tape** là công cụ tính đạo hàm của tensorflow. Cú pháp sau tính toán đạo hàm của hàm $y=x^2$ tại $x=4$, $(\\frac{δy}{δx| x=4} = 8)$:"
      ],
      "metadata": {
        "id": "DuwGSaiKnfFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(4.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(x) # x không phải là một tf.Variable => cần chỉ biến cần tape theo dõi, nếu không giá trị đạo hàm sẽ là 0.\n",
        "                  # nếu x là tf.Variable thì không cần watch\n",
        "    y = x ** 2\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFZOOrlxnvD1",
        "outputId": "9f896dcd-b56c-417c-d244-cef94498c03c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(8.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thực hiện đạo hàm cấp 2 với cú pháp như sau:"
      ],
      "metadata": {
        "id": "lVcDQq_6qCfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(4.0)\n",
        "\n",
        "with tf.GradientTape() as t2:\n",
        "    t2.watch(x)\n",
        "    with tf.GradientTape() as t:\n",
        "        t.watch(x)\n",
        "        y = x ** 2\n",
        "    dy_dx = t.gradient(y, x)\n",
        "d2y_dx = t2.gradient(dy_dx, x)\n",
        "print(d2y_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiGj-7x6qB7M",
        "outputId": "d996223c-50b8-42d2-b346-3b917eefc4c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple gradient descent pipeline"
      ],
      "metadata": {
        "id": "cTckZjALp6Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta sẽ xem xét một ví dụ xây dựng một mô hình hồi quy tuyến tính đơn giản:\n",
        "$Y = aX + b$ <br>\n",
        "\n"
      ],
      "metadata": {
        "id": "qN3ij3U5ZPFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant([1., 4., 6, 3, 3, 4, 5, 6, 7])\n",
        "Y = tf.constant([0.25, 1.2, 0.79, 0.52, 1.6, 1.7, 1.9, 2, 2])"
      ],
      "metadata": {
        "id": "een1tXwqeNVW"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong ví dụ này, $a$ và $b$ là các tham số của mô hình, chúng ta muốn tìm kiếm một giá trị tối ưu của chúng để mô hình khái quát hóa được mối quan hệ của 2 biến $X$, $Y$. Vì vậy, $a$ và $b$ trong ví dụ này là 2 biến một chiều (shape = (1,)). Ta thực hiện khai báo:"
      ],
      "metadata": {
        "id": "xypx1uaQeN1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.Variable(initial_value=0., trainable= True)\n",
        "b = tf.Variable(initial_value= 0., trainable= True)"
      ],
      "metadata": {
        "id": "UItvT9yqYpyD"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X và Y trong trường hợp này đại diện cho phần dữ liệu huấn luyện, vì vậy, chúng là các hằng số đã biết. Kích thước của chúng phụ thuộc chiều dài của batch size. <br>\n",
        "Ta định nghĩa một hàm loss đơn giản:"
      ],
      "metadata": {
        "id": "K_sZE1sVbYk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_true, y_pred):\n",
        "    return tf.reduce_sum(tf.square(y_true-y_pred))"
      ],
      "metadata": {
        "id": "5RUxbLbMazwT"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Để thực hiện huấn luyện mô hình, ta thực hiện các bước: tính giá trị dự đoán, tính giá trị hàm loss, tính đạo hàm riêng của hàm loss theo từng tham số, cập nhật lại giá trị tham số. Triển khai với Gradient tape có dạng như sau:"
      ],
      "metadata": {
        "id": "LhlWqk1Oe3Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "with tf.GradientTape(persistent =True) as tape:\n",
        "    y_pred = a*X+b\n",
        "    loss = loss_fn(Y, y_pred)\n",
        "\n",
        "# Tính đạo hàm riêng của loss theo từng tham số\n",
        "a_gradient = tape.gradient(loss, a)\n",
        "b_gradient = tape.gradient(loss, b)\n",
        "\n",
        "# Cập nhật lại giá trị các tham số: w1 = w0 - learning_rate * d(loss)/dw\n",
        "a.assign_sub(a_gradient*learning_rate)\n",
        "b.assign_sub(b_gradient*learning_rate)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGlI-w9-brr8",
        "outputId": "3d3b51ab-ccb2-498e-d459-36120009b7ba"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.116900004>\n",
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.023920001>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giá trị persistent =True cho phép tính được giá trị đạo hàm (tape.gradient) cho nhiều hơn 1 lần. <br>\n",
        "Để quan sát quá trình tối ưu, ta huấn luyện với nhiều epoch và kiểm tra giá trị hàm loss:"
      ],
      "metadata": {
        "id": "X-sEZmoJiHFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(x_true, y_true):\n",
        "    with tf.GradientTape(persistent =True) as tape:\n",
        "        # Tính giá trị dự đoán và giá trị hàm loss\n",
        "        y_pred = a*X+b\n",
        "        loss = loss_fn(Y, y_pred)\n",
        "        print(\"Loss: \", loss.numpy())\n",
        "\n",
        "    # Tính đạo hàm riêng của loss theo từng tham số\n",
        "    a_gradient = tape.gradient(loss, a)\n",
        "    b_gradient = tape.gradient(loss, b)\n",
        "\n",
        "    # Cập nhật lại giá trị các tham số: w1 = w0 - learning_rate * d(loss)/dw\n",
        "    a.assign_sub(a_gradient*learning_rate)\n",
        "    b.assign_sub(b_gradient*learning_rate)\n",
        "    print(\"model: Y= %s X + %s\"%(a.numpy(), b.numpy()))\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"Epoch: \", i)\n",
        "    train_step(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12O7157viGDL",
        "outputId": "2f048cef-ce7f-446d-ef32-67b73a64fc6a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "Loss:  8.134604\n",
            "model: Y= 0.18587564 X + 0.038291242\n",
            "Epoch:  1\n",
            "Loss:  4.186867\n",
            "model: Y= 0.22655392 X + 0.0470237\n",
            "Epoch:  2\n",
            "Loss:  2.8102624\n",
            "model: Y= 0.25052384 X + 0.052426066\n",
            "Epoch:  3\n",
            "Loss:  2.330071\n",
            "model: Y= 0.2646282 X + 0.055861536\n",
            "Epoch:  4\n",
            "Loss:  2.1624107\n",
            "model: Y= 0.2729075 X + 0.05813503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Có thể thấy giá trị hàm loss giảm theo thời gian và giá trị a, b dần hội tụ trở nên ổn định qua các epochs.<br>\n",
        "Hàm trên sử dụng Gradient descent cơ bản, trong thực tế ta sẽ mong muốn sử dụng các optimizer hiệu quả hơn. Ngoài ra, số lượng tham số của một mạng học sâu trong thực tế có thể lên đến hàng triệu tham số, và ta không muốn phải cập nhật tay cho từng tham số một. Khi đó, ta sẽ làm như sau:"
      ],
      "metadata": {
        "id": "Akh-LUpnkFIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer='zeros')\n",
        "])\n",
        "\n",
        "optimizer= tf.optimizers.Adam(learning_rate = .07)\n",
        "\n",
        "def train_step2(x_true, y_true):\n",
        "    with tf.GradientTape(persistent =True) as tape:\n",
        "        # Tính giá trị dự đoán và giá trị hàm loss\n",
        "        y_pred = model(tf.expand_dims(X,-1))\n",
        "        loss = loss_fn( tf.expand_dims(Y, -1), y_pred)\n",
        "        print(\"Loss: \", loss.numpy())\n",
        "\n",
        "    # Tính đạo hàm riêng của loss theo từng tham số\n",
        "    variables = model.trainable_variables \n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    # Cập nhật lại giá trị các tham số:\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    \n",
        "for i in range(5):\n",
        "    print(\"Epoch: \", i)\n",
        "    train_step2(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1P8n2daGzrH",
        "outputId": "ce38b8ef-e59a-4ac6-8831-befc67ddbe6e"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "Loss:  19.457\n",
            "Epoch:  1\n",
            "Loss:  10.9911995\n",
            "Epoch:  2\n",
            "Loss:  5.402389\n",
            "Epoch:  3\n",
            "Loss:  2.5634406\n",
            "Epoch:  4\n",
            "Loss:  2.0542033\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}